import os
import streamlit as st
import google.generativeai as genai
import PyPDF2
import pikepdf
import tempfile
import hashlib
from dotenv import load_dotenv

load_dotenv()
genai.configure(api_key=os.environ['GOOGLE_API_KEY'])

# Initialize session state
if 'uploaded_files' not in st.session_state:
    st.session_state.uploaded_files = []
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'text_cache' not in st.session_state:
    st.session_state.text_cache = {}

# Use Streamlit's caching
@st.cache_data
def extract_text_from_pdf_cached(file_content):
    """Cached function to extract text from PDF using file content hash as cache key"""
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as temp_file:
            temp_file.write(file_content)
            temp_file_path = temp_file.name
            
            with open(temp_file_path, 'rb') as pdf_file:
                pdf_reader = PyPDF2.PdfReader(pdf_file)
                extracted_text = ""
                for page in pdf_reader.pages:
                    try:
                        text = page.extract_text()
                        if text:
                            extracted_text += text + "\n\n"
                    except Exception:
                        continue

            os.unlink(temp_file_path)
            return extracted_text if extracted_text.strip() else None
    except Exception:
        return None

@st.cache_data
def extract_text_with_pikepdf_cached(file_content):
    """Cached function to extract text using pikepdf"""
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as temp_file:
            temp_file.write(file_content)
            temp_file_path = temp_file.name
            
            pdf = pikepdf.Pdf.open(temp_file_path)
            extracted_text = ""
            for page in pdf.pages:
                try:
                    text_extraction = page.extract_text()
                    if text_extraction:
                        extracted_text += text_extraction + "\n\n"
                except Exception:
                    continue

            os.unlink(temp_file_path)
            return extracted_text if extracted_text.strip() else None
    except Exception:
        return None

class PDFChatApp:
    def __init__(self):
        st.set_page_config(page_title="–ß–∞—Ç —Å PDF –∏ AI", page_icon="üìÑ", layout="wide")
        st.title(":books: –ß–∞—Ç —Å PDF")

    def process_documents(self):
        st.sidebar.header("üì§ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        
        # Clear cache button
        if st.sidebar.button("–û—á–∏—Å—Ç–∏—Ç—å –∫—ç—à"):
            st.session_state.text_cache = {}
            st.session_state.uploaded_files = []
            st.session_state.chat_history = []
            st.cache_data.clear()
            st.sidebar.success("–ö—ç—à –æ—á–∏—â–µ–Ω")
            return

        uploaded_files = st.sidebar.file_uploader(
            "–í—ã–±–µ—Ä–∏—Ç–µ PDF-—Ñ–∞–π–ª—ã",
            type=['pdf'],
            accept_multiple_files=True,
            key="pdf_uploader"
        )

        if uploaded_files:
            with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤..."):
                for uploaded_file in uploaded_files:
                    file_content = uploaded_file.read()
                    
                    # Create a hash of file content for caching
                    file_hash = hashlib.md5(file_content).hexdigest()
                    
                    # Check if text is already in cache
                    if file_hash in st.session_state.text_cache:
                        extracted_text = st.session_state.text_cache[file_hash]
                    else:
                        # Try different extraction methods
                        extracted_text = extract_text_from_pdf_cached(file_content)
                        if not extracted_text:
                            extracted_text = extract_text_with_pikepdf_cached(file_content)
                        
                        if extracted_text:
                            st.session_state.text_cache[file_hash] = extracted_text

                    if extracted_text:
                        try:
                            # Create temporary file for Gemini upload
                            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as temp_file:
                                temp_file.write(file_content)
                                gemini_file = genai.upload_file(temp_file.name)
                                os.unlink(temp_file.name)

                            if gemini_file:
                                # Store file info in session state
                                file_info = {
                                    'name': uploaded_file.name,
                                    'hash': file_hash,
                                    'gemini_file': gemini_file,
                                    'text': extracted_text
                                }
                                
                                # Check if file already exists in uploaded_files
                                existing_files = [f['hash'] for f in st.session_state.uploaded_files]
                                if file_hash not in existing_files:
                                    st.session_state.uploaded_files.append(file_info)
                                    st.sidebar.success(f"‚úÖ –§–∞–π–ª {uploaded_file.name} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω")
                                
                        except Exception as upload_error:
                            st.sidebar.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞ {uploaded_file.name}: {str(upload_error)}")
                    else:
                        st.sidebar.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞ {uploaded_file.name}")

    def chat_interface(self):
        st.header("üí¨ –í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏")

        if not st.session_state.uploaded_files:
            st.warning("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ PDF-—Ñ–∞–π–ª—ã –≤ –±–æ–∫–æ–≤–æ–º –º–µ–Ω—é")
            return

        col1, col2 = st.columns([2, 1])
        
        with col1:
            model_choice = st.selectbox(
                "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å Gemini",
                ["gemini-1.5-flash"],
                key="model_selector"
            )

            user_query = st.text_area(
                "–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å –∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º",
                height=100,
                key="query_input"
            )

            if st.button("–û—Ç–ø—Ä–∞–≤–∏—Ç—å –∑–∞–ø—Ä–æ—Å", key="submit_button"):
                if not user_query:
                    st.error("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å")
                    return

                try:
                    with st.spinner("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞..."):
                        model = genai.GenerativeModel(model_choice)
                        context = "\n\n".join([file['text'] for file in st.session_state.uploaded_files])
                        
                        prompt = f"""
                        –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ PDF-–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:
                        {context}

                        –í–æ–ø—Ä–æ—Å: {user_query}

                        –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏:
                        1. –í–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
                        2. –û—Ç–≤–µ—á–∞–π—Ç–µ –¢–û–õ–¨–ö–û –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                        3. –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω, —É–∫–∞–∂–∏—Ç–µ "–Ø –Ω–µ –º–æ–≥—É –Ω–∞–π—Ç–∏ –æ—Ç–≤–µ—Ç –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ"
                        4. –ë—É–¥—å—Ç–µ —Ç–æ—á–Ω—ã–º–∏ –∏ –ª–∞–∫–æ–Ω–∏—á–Ω—ã–º–∏
                        5. –°—Å—ã–ª–∞–π—Ç–µ—Å—å –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —á–∞—Å—Ç–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                        """

                        response = model.generate_content(prompt)
                        
                        st.success("ü§ñ –û—Ç–≤–µ—Ç:")
                        st.write(response.text)
                        
                        st.session_state.chat_history.append({
                            'query': user_query,
                            'response': response.text
                        })

                except Exception as e:
                    st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {str(e)}")

        with col2:
            if st.session_state.chat_history:
                st.subheader("üìú –ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞")
                for i, chat in enumerate(st.session_state.chat_history):
                    with st.expander(f"–î–∏–∞–ª–æ–≥ {i + 1}"):
                        st.markdown(f"**–í–æ–ø—Ä–æ—Å:** {chat['query']}")
                        st.markdown(f"**–û—Ç–≤–µ—Ç:** {chat['response']}")

    def run(self):
        self.process_documents()
        self.chat_interface()

if __name__ == "__main__":
    app = PDFChatApp()
    app.run()
